# âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import os
import re
import json
import requests
from dotenv import load_dotenv
from supabase import create_client
from datasets import load_dataset
import wikipedia
from wikipedia.exceptions import DisambiguationError, PageError
from bs4 import BeautifulSoup
from urllib.parse import quote_plus
from deep_translator import GoogleTranslator
from openai import OpenAI
from typing import Dict, Any, List
from .supabase_client import supabase

# âœ… í™˜ê²½ ì„¤ì •
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
client = OpenAI(api_key=OPENAI_KEY)

namuwiki_dataset = None

# âœ… ë‚˜ë¬´ìœ„í‚¤ ë‹¨ì¼ ê²€ìƒ‰ í•¨ìˆ˜
def get_namuwiki_text(species_name):
    print(f"\U0001F4E5 [get_namuwiki_text] ì¢…ì¡±ëª…: {species_name}")
    global namuwiki_dataset
    if namuwiki_dataset is None:
        namuwiki_dataset = load_dataset("heegyu/namuwiki", split="train")
    for entry in namuwiki_dataset:
        if entry["title"] == species_name:
            return entry["text"]
    print("âŒ ë‚˜ë¬´ìœ„í‚¤ ë³¸ë¬¸ ì—†ìŒ")
    return None

# âœ… ìœ„í‚¤í”¼ë””ì•„ í¬ë¡¤ëŸ¬
def get_wiki_species(species_name):
    print(f"\U0001F4E5 [get_wiki_species] ì¢…ì¡±ëª…: {species_name}")
    try:
        page = wikipedia.page(species_name, auto_suggest=False)
        return page.content.strip()
    except (DisambiguationError, PageError):
        return None
    except Exception as e:
        print(f"âŒ ìœ„í‚¤ ì˜ˆì™¸ ë°œìƒ: {e}")
        return None

# âœ… íŒ¬ë¤ í¬ë¡¤ëŸ¬
def translate_ko_to_en(text: str) -> str:
    print(f"\U0001F310 [translate_ko_to_en] ë²ˆì—­ ì‹œë„: {text}")
    try:
        translated = GoogleTranslator(source='ko', target='en').translate(text)
        result = translated.replace(" ", "_")
        return result
    except Exception as e:
        return text.replace(" ", "_")

def crawl_fandom(species_name_ko):
    print(f"\U0001F4E5 [crawl_fandom] ì¢…ì¡±ëª…: {species_name_ko}")
    species_name_en = translate_ko_to_en(species_name_ko)
    url = f"https://fiction.fandom.com/wiki/{quote_plus(species_name_en)}"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(url, headers=headers, timeout=10)
        if res.status_code != 200:
            return None
        soup = BeautifulSoup(res.text, "html.parser")
        content_div = soup.find("div", class_="mw-parser-output")
        if not content_div:
            return None
        paragraphs = content_div.find_all("p")
        text = "\n".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))
        if len(text) < 300:
            return None
        return text
    except Exception as e:
        return None

# âœ… GPT ìš”ì•½ í•¨ìˆ˜
def extract_json_block(text):
    print("ğŸ” [extract_json_block] JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„")
    match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
    return match.group(1) if match else text.strip()

def summarize_each_source(sources):
    summaries = []
    for i, src in enumerate(sources):
        try:
            res = client.chat.completions.create(
                model="gpt-4o",
                temperature=0.5,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íŒíƒ€ì§€ ì„¸ê³„ì˜ ì¢…ì¡±ë“¤ì— ëŒ€í•œ ë°±ê³¼ì‚¬ì „ í¸ì§‘ìì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ì¢…ì¡±ì˜ íŠ¹ì§•, ë¬¸í™”, ëŠ¥ë ¥, ë§íˆ¬ ë“±ì„ ì¶”ì¶œí•˜ì—¬ ìš”ì•½í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 5000ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. íŠ¹íˆ ì¢…ì¡±ì˜ íŠ¹ì§•ì ì¸ ë©´ì„ ì˜ ë‹´ì•„ì£¼ì„¸ìš”:\n\n{src}"}
                ]
            )
            summary = res.choices[0].message.content.strip()
            summaries.append(summary)
        except Exception as e:
            print(f"âŒ GPT ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            continue
    return summaries

def reduce_summaries_to_final_json(species_name, summaries):
    if not summaries:
        return None
    joined = "\n\n=== ë‹¤ìŒ ì¶œì²˜ ===\n\n".join(summaries)
    prompt = (
        f"ë‹¤ìŒì€ '{species_name}' ì¢…ì¡±ì— ëŒ€í•œ ì—¬ëŸ¬ ì¶œì²˜ì˜ ìš”ì•½ë¬¸ì…ë‹ˆë‹¤. "
        f"ì´ë¥¼ ì¢…í•©í•˜ì—¬ í•´ë‹¹ ì¢…ì¡±ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³ , ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”. "
        f"íŠ¹íˆ ì´ ì¢…ì¡±ë§Œì˜ ë…íŠ¹í•œ íŠ¹ì§•ê³¼ ë§íˆ¬ë¥¼ ì˜ í‘œí˜„í•´ì£¼ì„¸ìš”.\n\n"
        f"=== ì£¼ì˜ì‚¬í•­ ===\n"
        f"1. ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì£¼ì„¸ìš”.\n"
        f"2. JSON í˜•ì‹ì—ì„œ ë²—ì–´ë‚œ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n"
        f"3. ëª¨ë“  ë¬¸ìì—´ì€ ìŒë”°ì˜´í‘œ(\")ë¡œ ê°ì‹¸ì£¼ì„¸ìš”.\n"
        f"4. íŠ¹ì§•ì€ ì •í™•íˆ 5ê°œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"
        f"=== ìš”ì•½ë¬¸ ===\n{joined}\n\n"
        f"=== JSON í˜•ì‹ ===\n"
        f"""{{
            "ì¢…ì¡±ëª…": "{species_name}",
            "ìš”ì•½": "ì´ ì¢…ì¡±ì˜ í•µì‹¬ì ì¸ íŠ¹ì§•ì„ ì„¤ëª…í•˜ëŠ” 5000ì ì´ë‚´ì˜ í…ìŠ¤íŠ¸",
            "íŠ¹ì§•": [
                "ì´ ì¢…ì¡±ë§Œì˜ ëŒ€í‘œì ì¸ íŠ¹ì§• 1",
                "ì´ ì¢…ì¡±ë§Œì˜ ëŒ€í‘œì ì¸ íŠ¹ì§• 2",
                "ì´ ì¢…ì¡±ë§Œì˜ ëŒ€í‘œì ì¸ íŠ¹ì§• 3",
                "ì´ ì¢…ì¡±ë§Œì˜ ëŒ€í‘œì ì¸ íŠ¹ì§• 4",
                "ì´ ì¢…ì¡±ë§Œì˜ ëŒ€í‘œì ì¸ íŠ¹ì§• 5"
            ],
            "ë§íˆ¬": {{
                "ìŠ¤íƒ€ì¼": "ì´ ì¢…ì¡±ì´ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë§íˆ¬ë‚˜ ëŒ€í™” ìŠ¤íƒ€ì¼ ì„¤ëª…",
                "ì¢…ê²°ì–´ë¯¸": "ì´ ì¢…ì¡±ì´ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” íŠ¹ì§•ì ì¸ ì¢…ê²°ì–´ë¯¸ë‚˜ í‘œí˜„",
                "ì˜ˆì‹œ": "ì´ ì¢…ì¡±ì˜ ì „í˜•ì ì¸ ëŒ€í™” ì˜ˆì‹œ"
            }}
        }}"""
    )
    try:
        final_res = client.chat.completions.create(
            model="gpt-4o",
            temperature=0.6,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ íŒíƒ€ì§€ ì„¸ê³„ì˜ ì¢…ì¡±ë“¤ì— ëŒ€í•œ ë°±ê³¼ì‚¬ì „ í¸ì§‘ìì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì¢…ì¡±ì˜ íŠ¹ì§•ì„ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ ì œì‹œëœ JSON í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì•¼ í•˜ë©°, JSON í˜•ì‹ì—ì„œ ë²—ì–´ë‚œ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )
        raw = final_res.choices[0].message.content.strip()
        json_text = extract_json_block(raw)
        return json.loads(json_text)
    except Exception as e:
        print(f"âŒ ìµœì¢… ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# âœ… Supabaseì— ì €ì¥
def save_to_supabase(species_name, summary):
    res = supabase.table("species").insert({
        "name": species_name,
        "summary": summary
    }).execute()

    if res.data:
        print("âœ… Supabase ì €ì¥ ì„±ê³µ")
        return True
    else:
        print(f"âŒ Supabase ì €ì¥ ì‹¤íŒ¨: {res.error}")
        return False

# âœ… Supabase ì¤‘ë³µ í™•ì¸ í•¨ìˆ˜
def exists_in_supabase(species_name):
    try:
        res = supabase.table("species").select("name").eq("name", species_name).execute()
        return bool(res.data)
    except Exception as e:
        print(f"âŒ Supabase ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return False

# âœ… ì „ì²´ ì‹¤í–‰ í•¨ìˆ˜
def process_species(species_name):
    print(f"\nğŸš€ [process_species] ì¢…ì¡± '{species_name}' ì²˜ë¦¬ ì‹œì‘")

    if exists_in_supabase(species_name):
        print(f"âš ï¸ ì´ë¯¸ ì¡´ì¬: {species_name} â†’ ì²˜ë¦¬ ê±´ë„ˆëœ€")
        return

    sources = []

    fandom = crawl_fandom(species_name)
    if fandom:
        print("âœ… íŒ¬ë¤ í¬ë¡¤ë§ ì„±ê³µ")
        sources.append(fandom)
    else:
        print("âŒ íŒ¬ë¤ í¬ë¡¤ë§ ì‹¤íŒ¨")

    wiki = get_wiki_species(species_name)
    if wiki:
        print("âœ… ìœ„í‚¤ í¬ë¡¤ë§ ì„±ê³µ")
        sources.append(wiki)
    else:
        print("âŒ ìœ„í‚¤ í¬ë¡¤ë§ ì‹¤íŒ¨")

    namu = get_namuwiki_text(species_name)
    if namu:
        print("âœ… ë‚˜ë¬´ìœ„í‚¤ ê²€ìƒ‰ ì„±ê³µ")
        sources.append(namu)
    else:
        print("âŒ ë‚˜ë¬´ìœ„í‚¤ ê²€ìƒ‰ ì‹¤íŒ¨")

    if not sources:
        print(f"âŒ ì¶œì²˜ ì—†ìŒ: {species_name}")
        return

    print(f"ğŸ§  GPT ìš”ì•½ ì‹œì‘ (ì¶œì²˜ ìˆ˜: {len(sources)})")
    partials = summarize_each_source(sources)
    print("ğŸ“„ ë¶€ë¶„ ìš”ì•½ ë¦¬ìŠ¤íŠ¸:")
    for i, p in enumerate(partials):
        print(f"--- ìš”ì•½ {i+1} ---\n{p}\n")

    summary = reduce_summaries_to_final_json(species_name, partials)

    if summary:
        success = save_species_to_supabase(summary)
        if success:
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {species_name}")
        else:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {species_name}")
    else:
        print(f"âŒ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {species_name}")

def save_species_to_supabase(species_data: Dict[str, Any]) -> bool:
    """ì¢…ì¡± ì •ë³´ë¥¼ Supabaseì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        species_data: {
            "ì¢…ì¡±ëª…": str,
            "ìš”ì•½": str,
            "íŠ¹ì§•": List[str],
            "ë§íˆ¬": {
                "ìŠ¤íƒ€ì¼": str,
                "ì¢…ê²°ì–´ë¯¸": str,
                "ì˜ˆì‹œ": str
            }
        }
    """
    try:
        # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        existing = supabase.table("species").select("id").eq("name", species_data["ì¢…ì¡±ëª…"]).execute()
        
        if existing.data:
            print(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸: {species_data['ì¢…ì¡±ëª…']}")
            response = supabase.table("species").update({
                "summary": species_data["ìš”ì•½"],
                "traits": species_data["íŠ¹ì§•"],
                "speech_pattern": species_data["ë§íˆ¬"]
            }).eq("name", species_data["ì¢…ì¡±ëª…"]).execute()
        else:
            print(f"âœ¨ ìƒˆ ë°ì´í„° ì¶”ê°€: {species_data['ì¢…ì¡±ëª…']}")
            response = supabase.table("species").insert({
                "name": species_data["ì¢…ì¡±ëª…"],
                "summary": species_data["ìš”ì•½"],
                "traits": species_data["íŠ¹ì§•"],
                "speech_pattern": species_data["ë§íˆ¬"]
            }).execute()
        
        if not response.data:
            print(f"âŒ ì¢…ì¡± ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {species_data['ì¢…ì¡±ëª…']}")
            return False
            
        print(f"âœ… ì¢…ì¡± ì •ë³´ ì €ì¥ ì™„ë£Œ: {species_data['ì¢…ì¡±ëª…']}")
        return True
        
    except Exception as e:
        print(f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def get_species_info(species_name: str) -> Dict[str, Any]:
    """ì¢…ì¡± ì •ë³´ë¥¼ Supabaseì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        response = supabase.table("species").select("*").eq("name", species_name).execute()
        
        if not response.data:
            print(f"âš ï¸ ì¢…ì¡± ì •ë³´ ì—†ìŒ: {species_name}")
            return {}
            
        data = response.data[0]
        return {
            "name": data["name"],
            "summary": data["summary"],
            "traits": data.get("traits", []),
            "speech_pattern": data.get("speech_pattern", {
                "ìŠ¤íƒ€ì¼": "",
                "ì¢…ê²°ì–´ë¯¸": "",
                "ì˜ˆì‹œ": ""
            })
        }
        
    except Exception as e:
        print(f"âŒ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {}
